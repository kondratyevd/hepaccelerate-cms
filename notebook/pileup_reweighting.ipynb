{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chosen PU distribution can be extracted from the CMSSW configuration, but in 2017 a multithreading bug caused a mismatch between the chosen and actually generated conf (peaks at 0 etc)\n",
    "  - https://indico.cern.ch/event/695872/contributions/2877123/attachments/1593469/2522749/pileup_ppd_feb_2018.pdf\n",
    "\n",
    "Best is to extract MC PU profile directly from MC sample file, if per-file statistics are high enough\n",
    "  - NanoAODTools has an implementation\n",
    "  \n",
    "Systematic errors computed by varying MinBias xs by 5%\n",
    "  - https://twiki.cern.ch/twiki/bin/view/CMS/PileupSystematicErrors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import uproot, awkward\n",
    "#import uproot, cupy, awkward\n",
    "from awkward.util import numpy as anp\n",
    "import numpy as np\n",
    "import dask\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "import time\n",
    "\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all the files in the datasets (copied by hand to titans.hep.caltech.edu)\n",
    "files = {}\n",
    "files[\"dy\"] = glob.glob(\"/nvmedata/store/mc/RunIIFall17NanoAOD/DYJetsToLL_M-50_TuneCP5_13TeV-amcatnloFXFX-pythia8/NANOAODSIM/**/*.root\", recursive=True)\n",
    "files[\"ggh\"] = glob.glob(\"/nvmedata/store/mc/RunIIFall17NanoAOD/GluGluHToMuMu_M125_13TeV_amcatnloFXFX_pythia8/NANOAODSIM/**/*.root\", recursive=True)\n",
    "files[\"data_mu\"] = glob.glob(\"/nvmedata/store/data/Run2017*/SingleMuon/NANOAOD/**/*.root\", recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files[\"data_mu\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files[\"ggh\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Splits up a list of input files into main NanoAOD files and Friend files according to the main file name (UUID)\n",
    "\n",
    "filelist (List[str]): all input files\n",
    "\n",
    "returns two lists of same length, one for the main files, the other for the weighted files\n",
    "\n",
    "\"\"\"\n",
    "def pair_files(filelist):\n",
    "    friend_files = sorted([x for x in filelist if \"Friend\" in x])\n",
    "    regular_files = sorted([x for x in filelist if not \"Friend\" in x])\n",
    "    \n",
    "    files_nano = []\n",
    "    files_weights = []\n",
    "    \n",
    "    for fi in regular_files:\n",
    "        fn_base = os.path.splitext(os.path.basename(fi))[0]\n",
    "        matching_friend = [x for x in friend_files if fn_base in x]\n",
    "        assert(len(matching_friend)==1)\n",
    "        files_nano += [fi]\n",
    "        files_weights += [matching_friend[0]]\n",
    "        \n",
    "    return files_nano, files_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_ggh_nano, files_ggh_weights = pair_files(files[\"ggh\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(files_ggh_nano[0])\n",
    "print(files_ggh_weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loads a number of arrays from a file into memory using awkward-array\n",
    "fn (str) - input file name\n",
    "treename (str) - input tree name\n",
    "to_load (List[str]) - list of arrays to load\n",
    "\"\"\"\n",
    "def load_arrays(fn:str, treename: str, to_load: List[str]):\n",
    "    fi = uproot.open(fn)\n",
    "    tt = fi.get(treename)\n",
    "    arrs = tt.arrays(to_load)\n",
    "    return arrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple histogram datastructures\n",
    "def midpoints(arr):\n",
    "    return arr[:-1]# - np.diff(arr)\n",
    "\n",
    "class Histogram:\n",
    "    def __init__(self, contents, errors, edges):\n",
    "        self.contents = contents\n",
    "        self.errors = errors\n",
    "        self.edges = edges\n",
    "        \n",
    "    @staticmethod\n",
    "    def from_vector(data, bins, weights=None):\n",
    "        contents, edges = np.histogram(data, bins=bins, weights=weights)\n",
    "        return Histogram(contents, np.sqrt(contents), edges)\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        assert(np.all(self.edges == other.edges))\n",
    "        return Histogram(self.contents +  other.contents, np.sqrt(self.contents + other.contents), self.edges)\n",
    "\n",
    "    \n",
    "    def step(self, **kwargs):\n",
    "        line = plt.step(self.edges[:-1], self.contents, where=\"mid\", **kwargs)\n",
    "        self.errorbar(color=line[0].get_color())\n",
    "    \n",
    "    def errorbar(self, **kwargs):\n",
    "        plt.errorbar(midpoints(self.edges), self.contents, self.errors, lw=0, elinewidth=1, **kwargs)\n",
    "        \n",
    "    def normalized(self):\n",
    "        return Histogram(self.contents / np.sum(self.contents), np.sqrt(self.contents) / np.sum(self.contents), self.edges)\n",
    "    \n",
    "class Results(dict):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    def __add__(self, other):\n",
    "        d0 = self\n",
    "        d1 = other\n",
    "        \n",
    "        d_ret = Results({})\n",
    "        k0 = set(d0.keys())\n",
    "        k1 = set(d1.keys())\n",
    "\n",
    "        for k in k0.intersection(k1):\n",
    "            d_ret[k] = d0[k] + d1[k]\n",
    "\n",
    "        for k in k0.difference(k1):\n",
    "            d_ret[k] = d0[k]\n",
    "\n",
    "        for k in k1.difference(k0):\n",
    "            d_ret[k] = d1[k]\n",
    "\n",
    "        return d_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the raw data PU histogram\n",
    "def plot_data_hists_raw(fn):\n",
    "    fi = uproot.open(fn)\n",
    "\n",
    "    plt.figure(dpi=100)\n",
    "    fi[\"pileup\"].alledges[1:-1]\n",
    "    bins = fi[\"pileup\"].alledges[1:-1]\n",
    "    htrue = Histogram(fi[\"pileup\"].allvalues[1:-1], np.zeros(100), bins)\n",
    "    htrue_up = Histogram(fi[\"pileup_plus\"].allvalues[1:-1], np.zeros(100), bins)\n",
    "    htrue_down = Histogram(fi[\"pileup_minus\"].allvalues[1:-1], np.zeros(100), bins)\n",
    "\n",
    "    htrue.step(label=\"nominal\")\n",
    "    htrue_up.step(label=\"up\")\n",
    "    htrue_down.step(label=\"down\")\n",
    "    plt.legend(frameon=False)\n",
    "    \n",
    "    plt.xlabel(\"$N_{PV}$\", fontsize=20)\n",
    "    plt.ylabel(\"PDF (a.u.)\", fontsize=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_hists_raw(\"/nfshome/jpata/HmmAna/data/pileup/RunII_2016_data.root\")\n",
    "plt.title(\"$N_{PV}$ for data in 2016\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_hists_raw(\"/nfshome/jpata/HmmAna/data/pileup/RunII_2017_data.root\")\n",
    "plt.title(\"$N_{PV}$ for data in 2017\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_hists_raw(\"/nfshome/jpata/HmmAna/data/pileup/RunII_2018_data.root\")\n",
    "plt.title(\"2018\")\n",
    "plt.title(\"$N_{PV}$ for data in 2018ABC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://cms-nanoaod-integration.web.cern.ch/integration/master-102X/mc102X_doc.html\n",
    "arrays_to_load = [\n",
    "    \"PV_npvsGood\",\n",
    "    \"Pileup_nTrueInt\"\n",
    "]\n",
    "\n",
    "def process_mc(file_nano, file_weight):\n",
    "    arrs_ggh = load_arrays(file_nano, \"Events\", arrays_to_load)\n",
    "    arrs_ggh_weights = load_arrays(file_weight, \"Friends\", [\"puWeight\", \"puWeightUp\", \"puWeightDown\"])\n",
    "    \n",
    "    h1 = Histogram.from_vector(arrs_ggh[b\"PV_npvsGood\"], bins)\n",
    "    h2 = Histogram.from_vector(arrs_ggh[b\"Pileup_nTrueInt\"], bins)\n",
    "    h3 = Histogram.from_vector(arrs_ggh[b\"PV_npvsGood\"], bins, weights=arrs_ggh_weights[b\"puWeight\"])\n",
    "    h4 = Histogram.from_vector(arrs_ggh[b\"PV_npvsGood\"], bins, weights=arrs_ggh_weights[b\"puWeightUp\"])\n",
    "    h5 = Histogram.from_vector(arrs_ggh[b\"PV_npvsGood\"], bins, weights=arrs_ggh_weights[b\"puWeightDown\"])\n",
    "    \n",
    "    return Results({\"raw\": h1, \"gen\": h2, \"weighted\": h3, \"weighted_up\": h4, \"weighted_down\": h5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run for all MC (few seconds for signal)\n",
    "res = sum([process_mc(files_ggh_nano[i], files_ggh_weights[i]) for i in range(len(files_ggh_nano))], Results({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run for all data (few minutes for SingleMuon)\n",
    "hists_data = []\n",
    "\n",
    "f = IntProgress(min=0, max=len(files[\"data_mu\"])) # instantiate the bar\n",
    "display(f) # display the bar\n",
    "\n",
    "n_proc = 0\n",
    "t0 = time.time()\n",
    "for fi in files[\"data_mu\"]:\n",
    "    arrs = load_arrays(fi, \"Events\", [\"PV_npvsGood\"])\n",
    "    hh = Histogram.from_vector(arrs[b\"PV_npvsGood\"], bins)\n",
    "    f.value += 1\n",
    "    hists_data += [hh]\n",
    "    \n",
    "    n_proc += len(arrs[b\"PV_npvsGood\"])\n",
    "    \n",
    "t1 = time.time()\n",
    "print(\"processed {0:.2E} events at {1:.2E} Hz\".format(n_proc, n_proc/(t1 - t0)))\n",
    "\n",
    "hdata = hists_data[0]\n",
    "for h in hists_data[1:]:\n",
    "    hdata += h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5), dpi=200)\n",
    "a0 = plt.axes((0.0, 0.2, 1.0, 0.8))\n",
    "plt.title(\"partial 2017 validation\")\n",
    "plt.ylabel(\"normalized events\")\n",
    "\n",
    "hdata.normalized().errorbar(label=\"data\", marker=\"o\", color=\"black\")\n",
    "res[\"raw\"].normalized().step(label=\"raw\", color=\"gray\")\n",
    "\n",
    "res[\"weighted\"].normalized().step(label=\"PU weighted\", color=\"black\")\n",
    "res[\"weighted_up\"].normalized().step(label=\"PU weighted (up)\", color=\"red\")\n",
    "res[\"weighted_down\"].normalized().step(label=\"PU weighted (down)\", color=\"blue\")\n",
    "plt.legend(frameon=False)\n",
    "\n",
    "a1 = plt.axes((0.0, 0.0, 1.0, 0.15), sharex=a0)\n",
    "\n",
    "plt.plot(midpoints(hdata.edges), res[\"raw\"].normalized().contents / hdata.normalized().contents, color=\"gray\", lw=0, marker=\".\")\n",
    "\n",
    "plt.plot(midpoints(hdata.edges), res[\"weighted\"].normalized().contents / hdata.normalized().contents, color=\"black\", lw=0, marker=\".\")\n",
    "plt.plot(midpoints(hdata.edges), res[\"weighted_up\"].normalized().contents / hdata.normalized().contents, color=\"red\", lw=0, marker=\"^\", ms=4)\n",
    "plt.plot(midpoints(hdata.edges), res[\"weighted_down\"].normalized().contents / hdata.normalized().contents, color=\"blue\", lw=0, marker=\"v\", ms=4)\n",
    "\n",
    "plt.ylim(0,2)\n",
    "plt.xlim(10,60)\n",
    "plt.axhline(1.0, color=\"black\", lw=0.5)\n",
    "plt.xlabel(\"PV_npvsGood\", fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"1 0.172 9.39 3.48 3.27 1.35 1.41 0.947 1.23 0.602 1.75 1.58 1.51 1.36 1.16 1.07 1.08 1.07 1.14 1.14 1.2 1.2 1.22 1.25 1.27 1.27 1.27 1.27 1.26 1.28 1.25 1.22 1.16 1.12 1.04 0.97 0.926 0.868 0.838 0.789 0.748 0.751 0.803 0.869 0.945 1.1 1.27 1.43 1.49 1.55 1.5 1.31 1.18 0.953 0.735 0.571 0.41 0.285 0.195 0.136 0.0973 0.0691 0.0507 0.0388 0.03 0.0247 0.0173 0.0124 0.0107 0.0101 0.00954 0.00792 0.00796 0.0103 0.00683 0.00741 0.00497 0.00615 0.00544 0.0101 0.00864 0.00501 0.00661 0.00347 0.00376 1 1 0.00299 1 1 1 0.000453 1 1 1 1 1 1 1 1 1 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(map(float, s.split())))\n",
    "#plt.xlim(10,70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
